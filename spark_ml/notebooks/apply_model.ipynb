{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function2>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7, IntegerType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function2>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7, IntegerType)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StringType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector, pos:Integer) => prediction(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.0\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputStreamPath = /home/jovyan/data/events-stream\n",
       "modelPath = /home/jovyan/models/spark-ml-model-rf2\n",
       "dataSchema = StructType(StructField(tweet,StringType,true))\n",
       "inputDF = [tweet: string]\n",
       "sameModel = pipeline_b1b68980d298\n",
       "predictionsDF = [tweet: string, words: array<string> ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tweet: string, words: array<string> ... 5 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputStreamPath = \"/home/jovyan/data/events-stream\"\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model-rf2\"\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val inputDF = spark\n",
    "    .readStream\n",
    "    .schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .json(inputStreamPath)\n",
    "\n",
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model-rf2\")\n",
    "\n",
    "val predictionsDF = sameModel.transform(inputDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@36327560"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+----------+----------+\n",
      "|load_dttm              |tweets|positive,%|negative,%|\n",
      "+-----------------------+------+----------+----------+\n",
      "|2019-08-25 12:31:21.742|10    |20        |80        |\n",
      "+-----------------------+------+----------+----------+\n",
      "\n",
      "+-----------------------+------+----------+----------+\n",
      "|load_dttm              |tweets|positive,%|negative,%|\n",
      "+-----------------------+------+----------+----------+\n",
      "|2019-08-25 12:31:31.146|18    |27        |72        |\n",
      "+-----------------------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Streaming\n",
    "\n",
    "predictionsDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) => \n",
    "    batchDF\n",
    "    .withColumn(\"negative_probability\",getProbability($\"probability\",lit(0)))\n",
    "    .withColumn(\"positive_probability\",getProbability($\"probability\",lit(1)))\n",
    "    .withColumn(\"positive\", when($\"predictedLabel\"===0,1))\n",
    "    .withColumn(\"negative\", when($\"predictedLabel\"===1,1))\n",
    "    .withColumn(\"timestamp\", expr(\"current_timestamp\"))\n",
    "    .withWatermark(\"timestamp\", \"10 seconds\")\n",
    "    .groupBy(\n",
    "      window($\"timestamp\", \"10 seconds\"))\n",
    "    .agg(count($\"*\").as(\"tweets\")\n",
    "       ,sum(\"positive\").as(\"positive\")\n",
    "       ,sum(\"negative\").as(\"negative\")\n",
    "        )\n",
    "    \n",
    "   .selectExpr( \"current_timestamp() as load_dttm\"\n",
    "              , \"tweets\"\n",
    "              , \"cast(positive/tweets*100.0 as int) as `positive,%`\"\n",
    "              , \"cast(negative/tweets*100.0 as int) `negative,%`\")\n",
    "    .show(false)\n",
    "    \n",
    "}.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
